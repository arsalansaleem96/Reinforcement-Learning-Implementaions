{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d722e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_chess\n",
    "import chess\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43b132a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Chess-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b32486e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,exploration_rate,min_exploration_rate,max_exploration_rate,exploration_decay_rate,num_episodes,learning_rate,discount_rate,avg_num_episodes):\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.min_exploration_rate = min_exploration_rate\n",
    "        self.max_exploration_rate = max_exploration_rate\n",
    "        self.exploration_decay_rate = exploration_decay_rate\n",
    "        self.num_episodes = num_episodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        self.avg_num_episodes = avg_num_episodes\n",
    "        self.rewards_all_episodes = []\n",
    "        self.q_table = {}\n",
    "    \n",
    "    def getMoves(self,legal_moves):\n",
    "        return str([str(move) for move in list(legal_moves)])\n",
    "    def isLegalAction(self,action,legal_moves):\n",
    "        return True if action in legal_moves else False\n",
    "    def Play(self):\n",
    "        for episode in range(num_episodes):\n",
    "            finished = False\n",
    "            iteration_counts = 0\n",
    "            rewards_current_episode = 0\n",
    "\n",
    "            state = env.reset()\n",
    "            previous_action = None\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\n",
    "    #         print(env.render(mode='unicode'))\n",
    "\n",
    "            while not finished:\n",
    "                if state.is_checkmate() or state.is_stalemate() or state.is_insufficient_material() or state.is_game_over() or state.can_claim_threefold_repetition() or state.can_claim_fifty_moves() or state.can_claim_draw() or state.is_fivefold_repetition() or state.is_seventyfive_moves():\n",
    "                    finished = True\n",
    "                if finished:\n",
    "    #                 print(state.)\n",
    "    #                 print('Game Finished')\n",
    "    #                 print(env.render(mode='unicode'))\n",
    "    #                 time.sleep(2)\n",
    "                    break\n",
    "                else:\n",
    "    #                 print(env.render(mode='unicode'))\n",
    "                    previous_state = self.getMoves(state.legal_moves)\n",
    "\n",
    "\n",
    "                    # Exploration-exploitation trade-off\n",
    "                    self.exploration_rate_threshold = random.uniform(0, 1)\n",
    "                    if self.exploration_rate_threshold > self.exploration_rate:\n",
    "                        if previous_state in self.q_table:\n",
    "                            current_action = np.argmax(self.q_table[previous_state]) # Exploitation\n",
    "                            if not self.isLegalAction(current_action, state.legal_moves):\n",
    "                                current_action = random.choice(list(state.legal_moves)) # Exploration\n",
    "                        else:\n",
    "                            current_action = random.choice(list(state.legal_moves)) # Exploration\n",
    "                    else:\n",
    "                        current_action = random.choice(list(state.legal_moves)) # Exploration\n",
    "\n",
    "\n",
    "                        new_state, reward, done, info = env.step(current_action)\n",
    "\n",
    "                        if iteration_counts >= 1:\n",
    "\n",
    "                            current_state = self.getMoves(new_state.legal_moves)\n",
    "\n",
    "                            if self.q_table.get(previous_state) is None:\n",
    "                                self.q_table[previous_state] = {previous_action:0}\n",
    "\n",
    "                            if self.q_table.get(current_state) is None:\n",
    "                                self.q_table[current_state] = {current_action:0}\n",
    "\n",
    "                            if current_action in self.q_table[current_state] and previous_action in self.q_table[previous_state]:\n",
    "\n",
    "                                self.q_table[previous_state][previous_action] = self.q_table[previous_state][previous_action]  + \\\n",
    "                                    self.learning_rate * (reward + self.discount_rate * self.q_table[current_state][current_action] - self.q_table[previous_state][previous_action])\n",
    "\n",
    "                        state = new_state\n",
    "                        previous_action = current_action\n",
    "                        iteration_counts += 1\n",
    "                        rewards_current_episode += reward\n",
    "\n",
    "            # Exploration rate decay\n",
    "            self.exploration_rate = self.min_exploration_rate + \\\n",
    "                (self.max_exploration_rate - self.min_exploration_rate) * np.exp(-self.exploration_decay_rate*episode)\n",
    "\n",
    "            self.rewards_all_episodes.append(rewards_current_episode)\n",
    "\n",
    "        # Calculate and print the average reward per thousand episodes\n",
    "\n",
    "        rewards_per_thousand_episodes = np.split(np.array(self.rewards_all_episodes),self.num_episodes/self.avg_num_episodes)\n",
    "        count = self.avg_num_episodes\n",
    "\n",
    "        print(\"********Average reward per \"+str(self.avg_num_episodes)+\" episodes********\\n\")\n",
    "        for r in rewards_per_thousand_episodes:\n",
    "            print(count, \": \", str(sum(r/self.avg_num_episodes)))\n",
    "            count += self.avg_num_episodes\n",
    "\n",
    "        env.close()\n",
    "        return self.q_table\n",
    "    \n",
    "    \n",
    "    def PlayWithPolicy(self,q_table):\n",
    "        for episode in range(num_episodes):\n",
    "            finished = False\n",
    "            rewards_current_episode = 0\n",
    "\n",
    "            state = env.reset()\n",
    "            previous_action = None\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\n",
    "#             print(env.render(mode='unicode'))\n",
    "\n",
    "            while not finished:\n",
    "                if state.is_checkmate() or state.is_stalemate() or state.is_insufficient_material() or state.is_game_over() or state.can_claim_threefold_repetition() or state.can_claim_fifty_moves() or state.can_claim_draw() or state.is_fivefold_repetition() or state.is_seventyfive_moves():\n",
    "                    finished = True\n",
    "                if finished:\n",
    "#                     print('Game Finished')\n",
    "#                     print(env.render(mode='unicode'))\n",
    "#                     time.sleep(2)\n",
    "                    break\n",
    "                else:\n",
    "                    action = None\n",
    "    #                 print(env.render(mode='unicode'))\n",
    "                    previous_state = self.getMoves(state.legal_moves)\n",
    "\n",
    "                    if previous_state in self.q_table:\n",
    "                        action = np.argmax(q_table[previous_state]) # Exploitation\n",
    "                        if not self.isLegalAction(action, state.legal_moves):\n",
    "                            action = random.choice(list(state.legal_moves)) # Exploration\n",
    "                    else:\n",
    "                        action = random.choice(list(state.legal_moves)) # Exploration\n",
    "\n",
    "                        \n",
    "                    new_state, reward, done, info = env.step(action)\n",
    "\n",
    "                    state = new_state\n",
    "                    rewards_current_episode += reward\n",
    "\n",
    "            self.rewards_all_episodes.append(rewards_current_episode)\n",
    "\n",
    "        # Calculate and print the average reward per thousand episodes\n",
    "\n",
    "        rewards_per_thousand_episodes = np.split(np.array(self.rewards_all_episodes),self.num_episodes/self.avg_num_episodes)\n",
    "        count = self.avg_num_episodes\n",
    "\n",
    "        print(\"********Average reward per \"+str(self.avg_num_episodes)+\" episodes********\\n\")\n",
    "        for r in rewards_per_thousand_episodes:\n",
    "            print(count, \": \", str(sum(r/self.avg_num_episodes)))\n",
    "            count += self.avg_num_episodes\n",
    "\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6181690",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000\n",
    "avg_num_episodes = round(num_episodes/10)\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount_rate = 0.99\n",
    "\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "84dadc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(exploration_rate,min_exploration_rate,max_exploration_rate,exploration_decay_rate,num_episodes,learning_rate,discount_rate,avg_num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5901b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****EPISODE  1000 *****\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********Average reward per 100 episodes********\n",
      "\n",
      "100 :  -0.019999999999999997\n",
      "200 :  -0.02\n",
      "300 :  0.04\n",
      "400 :  -0.01\n",
      "500 :  -0.04\n",
      "600 :  -0.010000000000000004\n",
      "700 :  0.03\n",
      "800 :  3.469446951953614e-18\n",
      "900 :  -0.05\n",
      "1000 :  0.04\n"
     ]
    }
   ],
   "source": [
    "Q_table = agent.Play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1400940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****EPISODE  1000 *****\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********Average reward per 100 episodes********\n",
      "\n",
      "100 :  -0.04\n",
      "200 :  0.03\n",
      "300 :  -0.05\n",
      "400 :  0.03\n",
      "500 :  -0.009999999999999997\n",
      "600 :  0.03\n",
      "700 :  -0.05\n",
      "800 :  3.469446951953614e-18\n",
      "900 :  0.09\n",
      "1000 :  0.16\n"
     ]
    }
   ],
   "source": [
    "agent.PlayWithPolicy(Q_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
